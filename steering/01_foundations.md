# Mathematical Foundations

## 1. Notation and Definitions

### 1.1 Basic Notation

- **â„•**: Natural numbers {0, 1, 2, ...}
- **â„¤**: Integers {..., -2, -1, 0, 1, 2, ...}
- **â„**: Real numbers
- **{0,1}â¿**: Binary strings of length n
- **{0,1}***: All finite binary strings
- **|x|**: Bit length of x
- **x â† S**: Sample x uniformly from set S
- **x âˆ¥ y**: Concatenation of x and y
- **âŠ•**: XOR (exclusive OR) operation

### 1.2 Functions

**Definition 1.1** (Hash Function)
A hash function H: {0,1}* â†’ {0,1}â¿ maps arbitrary-length inputs to fixed-length outputs.

**Definition 1.2** (Collision Resistance)
A hash function H is (t, Îµ)-collision resistant if no algorithm running in time t can find x â‰  y with H(x) = H(y) with probability > Îµ.

**Definition 1.3** (Preimage Resistance)
A hash function H is (t, Îµ)-preimage resistant if given y = H(x) for random x, no algorithm running in time t can find x' with H(x') = y with probability > Îµ.

### 1.3 Computational Complexity

**Definition 1.4** (Time Complexity)
- **O(f(n))**: Upper bound - grows at most as fast as f(n)
- **Î©(f(n))**: Lower bound - grows at least as fast as f(n)
- **Î˜(f(n))**: Tight bound - grows exactly as fast as f(n)

**Definition 1.5** (Polynomial Time)
An algorithm runs in polynomial time if its time complexity is O(ná¶œ) for some constant c.

**Definition 1.6** (Exponential Time)
An algorithm runs in exponential time if its time complexity is Î©(2^(náµƒ)) for some constant a > 0.

### 1.4 Probability Theory

**Definition 1.7** (Probability Space)
A probability space (Î©, F, â„™) consists of:
- Î©: Sample space (set of all outcomes)
- F: Event space (Ïƒ-algebra of subsets of Î©)
- â„™: Probability measure â„™: F â†’ [0,1]

**Definition 1.8** (Expected Value)
For discrete random variable X:
```
ğ”¼[X] = Î£ xáµ¢ Â· â„™[X = xáµ¢]
```

**Definition 1.9** (Independence)
Events A and B are independent if:
```
â„™[A âˆ© B] = â„™[A] Â· â„™[B]
```

## 2. Cryptographic Primitives

### 2.1 One-Way Functions

**Definition 2.1** (One-Way Function)
A function f: {0,1}* â†’ {0,1}* is (t, Îµ)-one-way if:
1. f is efficiently computable (polynomial time)
2. For all algorithms A running in time t:
   ```
   â„™[f(A(f(x), 1â¿)) = f(x)] < Îµ
   ```
   where x â† {0,1}â¿

**Theorem 2.1** (OWF Existence)
If one-way functions exist, then â„™ â‰  NP.

*Proof sketch*: If â„™ = NP, then inverting f(x) is in â„™ (finding preimage), contradicting one-wayness. âˆ

### 2.2 Pseudorandom Functions

**Definition 2.2** (PRF)
A function family F = {fâ‚–: {0,1}â¿ â†’ {0,1}â¿}â‚–âˆˆğ’¦ is a (t, q, Îµ)-pseudorandom function if for all algorithms A making at most q queries in time t:
```
|â„™[A^(fâ‚–)(1â¿) = 1] - â„™[A^R(1â¿) = 1]| < Îµ
```
where k â† ğ’¦ and R is a truly random function.

### 2.3 Random Oracle Model

**Definition 2.3** (Random Oracle)
A random oracle H: {0,1}* â†’ {0,1}â¿ is a truly random function accessible to all parties (including adversaries) via oracle queries.

**Assumption 2.1** (Random Oracle Assumption)
For security analysis, we model hash functions (SHA-256, SHA-3, etc.) as random oracles.

## 3. Memory-Hard Functions

### 3.1 Time-Space Tradeoffs

**Definition 3.1** (Time-Space Complexity)
A function f has time-space complexity TÂ·S if:
- Fastest algorithm requires time T with space S
- Cannot be computed in time T' < T with space S' < S without T'Â·S' â‰¥ TÂ·S

**Definition 3.2** (Memory-Hard Function)
A function f: {0,1}* â†’ {0,1}â¿ is (S, T)-memory-hard if:
1. The intended algorithm uses space S and time T
2. Any algorithm using space S' < S requires time T' with T'Â·S' â‰¥ TÂ·S

### 3.2 Pebbling Complexity

**Definition 3.3** (Pebbling Game)
Given a directed acyclic graph (DAG) G = (V, E):
- Place pebbles on vertices (represents memory usage)
- Rules:
  - Can place pebble on v if all parents pebbled
  - Can remove pebble from any vertex
  - Goal: Pebble target vertex t
- Space complexity: Maximum pebbles used simultaneously
- Time complexity: Number of pebbling steps

**Theorem 3.1** (Pebbling Lower Bound - Paul-Tarjan-Celoni)
For depth-robust graphs with n vertices, any pebbling strategy requires either:
- Space Î©(n), or
- TimeÂ·Space Î©(nÂ²)

*Proof*: See Paul, Tarjan, Celoni (1977) "Space bounds for a game on graphs" âˆ

## 4. Lattice-Based Cryptography

### 4.1 Lattices

**Definition 4.1** (Lattice)
Given linearly independent vectors ***b***â‚, ..., ***b***â‚™ âˆˆ â„áµ, the lattice Î› is:
```
Î› = {Î£áµ¢ záµ¢***b***áµ¢ : záµ¢ âˆˆ â„¤}
```

The vectors {***b***áµ¢} form a basis of Î›.

**Definition 4.2** (Shortest Vector Problem - SVP)
Given a lattice basis, find the shortest non-zero vector in the lattice:
```
SVP(Î›) = min{||***v***|| : ***v*** âˆˆ Î› \ {0}}
```

**Theorem 4.1** (SVP Hardness)
SVP is NP-hard for â„“_âˆ norm (Ajtai 1998) and NP-hard to approximate within certain factors for â„“â‚‚ norm.

### 4.2 Learning With Errors (LWE)

**Definition 4.3** (LWE Distribution)
Given security parameter n, modulus q, and error distribution Ï‡ over â„¤_q:
- Secret: ***s*** â† â„¤_qâ¿
- Sample: (***a***, b = âŸ¨***a***, ***s***âŸ© + e mod q)
  where ***a*** â† â„¤_qâ¿ and e â† Ï‡

**Problem 4.1** (LWE Decision Problem)
Distinguish between:
- (***a***áµ¢, báµ¢ = âŸ¨***a***áµ¢, ***s***âŸ© + eáµ¢ mod q) for fixed secret ***s***
- (***a***áµ¢, uáµ¢) where uáµ¢ â† â„¤_q are uniform

**Theorem 4.2** (LWE Hardness - Regev 2005)
For appropriate parameters, LWE is at least as hard as quantumly solving worst-case lattice problems (GapSVP, SIVP) with approximation factor Ã•(n/Î±) where Î± is the error rate.

*Implications*: Breaking LWE-based schemes requires breaking worst-case hard lattice problems.

### 4.3 Module-LWE (ML-KEM/ML-DSA)

**Definition 4.4** (Module-LWE)
Generalization of LWE over polynomial rings R_q = â„¤_q[X]/(X^n + 1):
- Secret: ***s*** âˆˆ R_q^k (module of rank k)
- Sample: (***a***, b = ***a***^T Â· ***s*** + e mod q)
  where ***a*** â† R_q^k and e â† Ï‡^k

**Theorem 4.3** (MLWE Hardness)
MLWE reduces to Ring-LWE, which reduces to worst-case ideal lattice problems.

## 5. Quantum Computing Basics

### 5.1 Quantum States

**Definition 5.1** (Qubit)
A qubit is a unit vector in â„‚Â²:
```
|ÏˆâŸ© = Î±|0âŸ© + Î²|1âŸ©
where |Î±|Â² + |Î²|Â² = 1
```

**Definition 5.2** (Quantum Register)
An n-qubit register is a unit vector in (â„‚Â²)^âŠ—n â‰… â„‚^(2â¿):
```
|ÏˆâŸ© = Î£áµ¢ Î±áµ¢|iâŸ©
where Î£áµ¢ |Î±áµ¢|Â² = 1
```

### 5.2 Quantum Algorithms

**Theorem 5.1** (Shor's Algorithm - 1994)
Quantum computers can factor n-bit integers in time O(nÂ² log n log log n) using O(n) qubits.

**Theorem 5.2** (Grover's Algorithm - 1996)
Quantum computers can search an unsorted database of N items in time O(âˆšN) using O(log N) qubits.

**Corollary 5.1** (Hash Function Security)
If a hash function has n-bit output and 2^n classical security:
- Shor's algorithm: No advantage (no structure to exploit)
- Grover's algorithm: Reduces security to 2^(n/2)

*Conclusion*: Double the output length to maintain n-bit quantum security.

### 5.3 Quantum Limitations

**Theorem 5.3** (Decoherence Time Bound)
A quantum computer with error rate Îµ requires error correction overhead:
```
O(poly(1/Îµ))
```

**Fact 5.1** (Current Quantum Computers - 2025)
- Coherent qubits: ~1000 (Google, IBM)
- Coherence time: ~100 Î¼s
- Error rate: ~0.1% per gate
- Effective quantum RAM: ~125 KB

**Theorem 5.4** (Quantum RAM Requirements - Grassl et al.)
To apply Grover's algorithm to break a cryptographic hash with work factor W:
```
Quantum RAM needed: Î©(logÂ² W)
Quantum coherence time: Î©(âˆšW)
```

For W = 2^128:
- Quantum RAM: Î©(16 KB) for algorithm state
- Additional RAM for target data
- Coherence time: Î©(2^64) operations at gate time ~1 Î¼s = 10^13 years

**Corollary 5.2** (Quantum Computer Impossibility for QuantumWall)
QuantumWall's memory requirements (1 GB) exceed quantum RAM capabilities by factor of:
```
1 GB / 125 KB â‰ˆ 8,000Ã—
```

Even with perfect quantum computers, the memory wall remains.

## 6. Information-Theoretic Security

### 6.1 Entropy

**Definition 6.1** (Shannon Entropy)
For discrete random variable X:
```
H(X) = -Î£ â„™[X = x] Â· logâ‚‚ â„™[X = x]
```

**Definition 6.2** (Min-Entropy)
```
H_âˆ(X) = -logâ‚‚(max â„™[X = x])
```

**Definition 6.3** (Conditional Entropy)
```
H(X|Y) = Î£ â„™[Y = y] Â· H(X|Y = y)
```

### 6.2 Perfect Secrecy

**Definition 6.4** (Perfect Secrecy - Shannon)
An encryption scheme (E, D) has perfect secrecy if for all messages m, m' and ciphertext c:
```
â„™[M = m | C = c] = â„™[M = m]
```

**Theorem 6.1** (Shannon's Theorem)
Perfect secrecy requires |ğ’¦| â‰¥ |â„³| (key space â‰¥ message space).

**Corollary 6.1** (One-Time Pad)
XOR with random key achieves perfect secrecy:
```
c = m âŠ• k where k â† {0,1}â¿
```

## 7. Thermodynamic Limits

### 7.1 Landauer's Principle

**Theorem 7.1** (Landauer 1961)
Erasing one bit of information at temperature T requires minimum energy:
```
E â‰¥ káµ¦T ln 2
```
where káµ¦ â‰ˆ 1.38Ã—10^(-23) J/K (Boltzmann constant).

**Corollary 7.1** (Computational Energy Bound)
At room temperature (T = 300K):
```
E_bit â‰¥ 2.87Ã—10^(-21) J per bit erased
```

**Application 7.1** (Brute-Force Attack Energy)
To try all 2^128 keys:
```
E â‰¥ 2^128 Â· 2.87Ã—10^(-21) J
  â‰ˆ 9.75Ã—10^17 J
  â‰ˆ 2.7Ã—10^11 kWh
  â‰ˆ 30 years of global energy production
```

**Conclusion**: Even with perfect efficiency, brute-force attacks are physically impossible for large key spaces.

## 8. Reduction Proofs

### 8.1 Security Reductions

**Definition 8.1** (Security Reduction)
To prove scheme S is secure assuming problem P is hard:
1. Assume adversary A breaks S with probability Îµ in time t
2. Construct algorithm B that uses A to solve P
3. Show B solves P with probability Îµ' in time t'
4. If Îµ' and t' contradict hardness of P, then A cannot exist

**Theorem 8.1** (Reduction Tightness)
A reduction is tight if:
```
Îµ' â‰ˆ Îµ (same success probability)
t' â‰ˆ t (same running time)
```

Loose reductions require stronger assumptions.

### 8.2 Black-Box Reductions

**Definition 8.2** (Black-Box Reduction)
Algorithm B uses adversary A as a black box (oracle) without knowledge of A's internals.

**Theorem 8.2** (Black-Box Impossibility - Impagliazzo-Rudich)
Certain reductions cannot be proven black-box (e.g., one-way functions from complexity assumptions alone).

## 9. Provable Security Models

### 9.1 Standard Model

Security holds under standard computational assumptions (no idealized components).

### 9.2 Random Oracle Model (ROM)

Hash functions modeled as random oracles (accessible via queries only).

**Advantages**:
- Enables simpler proofs
- Captures intuition about hash functions

**Disadvantages**:
- Real hash functions are not random oracles
- ROM-secure schemes can be insecure in reality (though rare)

### 9.3 Generic Group Model

Adversary has no special knowledge of group structure (only black-box group operations).

## 10. References

1. **Goldreich, O.** (2001). "Foundations of Cryptography: Volume 1, Basic Tools"
2. **Katz, J. & Lindell, Y.** (2020). "Introduction to Modern Cryptography, 3rd Edition"
3. **Regev, O.** (2005). "On Lattices, Learning with Errors, Random Linear Codes, and Cryptography"
4. **Shor, P.** (1997). "Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer"
5. **Grover, L.** (1996). "A Fast Quantum Mechanical Algorithm for Database Search"
6. **Landauer, R.** (1961). "Irreversibility and Heat Generation in the Computing Process"
7. **Shannon, C.** (1949). "Communication Theory of Secrecy Systems"
8. **Paul, W., Tarjan, R., & Celoni, J.** (1977). "Space Bounds for a Game on Graphs"

---

**Next**: [02_bandwidth_hard.md](02_bandwidth_hard.md) - Bandwidth-Hard Functions
